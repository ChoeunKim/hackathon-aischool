# openai_api_whisper.py
from openai import OpenAI
from dotenv import load_dotenv
import os

# ë£¨íŠ¸ ê²½ë¡œ ê³„ì‚° (.../sub)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì§€ì • (ì ˆëŒ€ê²½ë¡œë¡œ ì•ˆì „í•˜ê²Œ)
audio_file_path = os.path.join(BASE_DIR, 'app', 'audio', 'test2.mp3')

# .env ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv(os.path.join(BASE_DIR, '.env'))

# API í‚¤ ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=api_key)

# ìŒì„± íŒŒì¼ ì—´ê¸°
with open(audio_file_path, 'rb') as audio_file:
    transcription = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file
    )

print("ğŸ§ ì¸ì‹ëœ í…ìŠ¤íŠ¸:")
print(transcription.text)
